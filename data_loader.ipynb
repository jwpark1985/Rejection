{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_loader.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jwpark1985/Rejection/blob/master/data_loader.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "1hs-RBSvxUsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "c388395e-5125-498d-e5ca-2e25009d3aed"
      },
      "cell_type": "code",
      "source": [
        "# original code is from https://github.com/aaron-xichen/pytorch-playground\n",
        "# modified by Kimin Lee\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import numpy.random as nr\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "def getSVHN(batch_size, img_size=32, data_root='/tmp/public_dataset/pytorch', train=True, val=True, **kwargs):\n",
        "    data_root = os.path.expanduser(os.path.join(data_root, 'svhn-data'))\n",
        "    num_workers = kwargs.setdefault('num_workers', 1)\n",
        "    kwargs.pop('input_size', None)\n",
        "    print(\"Building SVHN data loader with {} workers\".format(num_workers))\n",
        "\n",
        "    def target_transform(target):\n",
        "        new_target = target - 1\n",
        "        if new_target == -1:\n",
        "            new_target = 9\n",
        "        return new_target\n",
        "\n",
        "    ds = []\n",
        "    if train:\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            datasets.SVHN(\n",
        "                root=data_root, split='train', download=True,\n",
        "                transform=transforms.Compose([\n",
        "                    transforms.Scale(img_size),\n",
        "                    transforms.ToTensor(),\n",
        "                ]),\n",
        "                target_transform=target_transform,\n",
        "            ),\n",
        "            batch_size=batch_size, shuffle=True, **kwargs)\n",
        "        ds.append(train_loader)\n",
        "\n",
        "    if val:\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            datasets.SVHN(\n",
        "                root=data_root, split='test', download=True,\n",
        "                transform=transforms.Compose([\n",
        "                    transforms.Scale(img_size),\n",
        "                    transforms.ToTensor(),\n",
        "                ]),\n",
        "                target_transform=target_transform\n",
        "            ),\n",
        "            batch_size=batch_size, shuffle=False, **kwargs)\n",
        "        ds.append(test_loader)\n",
        "    ds = ds[0] if len(ds) == 1 else ds\n",
        "    return ds\n",
        "\n",
        "def getCIFAR10(batch_size, img_size=32, data_root='/tmp/public_dataset/pytorch', train=True, val=True, **kwargs):\n",
        "    data_root = os.path.expanduser(os.path.join(data_root, 'cifar10-data'))\n",
        "    num_workers = kwargs.setdefault('num_workers', 1)\n",
        "    kwargs.pop('input_size', None)\n",
        "    print(\"Building CIFAR-10 data loader with {} workers\".format(num_workers))\n",
        "    ds = []\n",
        "    if train:\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            datasets.CIFAR10(\n",
        "                root=data_root, train=True, download=True,\n",
        "                transform=transforms.Compose([\n",
        "                    transforms.Scale(img_size),\n",
        "                    transforms.ToTensor(),\n",
        "                ])),\n",
        "            batch_size=batch_size, shuffle=True, **kwargs)\n",
        "        ds.append(train_loader)\n",
        "    if val:\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            datasets.CIFAR10(\n",
        "                root=data_root, train=False, download=True,\n",
        "                transform=transforms.Compose([\n",
        "                    transforms.Scale(img_size),\n",
        "                    transforms.ToTensor(),\n",
        "                ])),\n",
        "            batch_size=batch_size, shuffle=False, **kwargs)\n",
        "        ds.append(test_loader)\n",
        "    ds = ds[0] if len(ds) == 1 else ds\n",
        "    return ds\n",
        "\n",
        "\n",
        "def getTargetDataSet(data_type, batch_size, imageSize, dataroot):\n",
        "    if data_type == 'cifar10':\n",
        "        train_loader, test_loader = getCIFAR10(batch_size=batch_size, img_size=imageSize, data_root=dataroot, num_workers=1)\n",
        "    elif data_type == 'svhn':\n",
        "        train_loader, test_loader = getSVHN(batch_size=batch_size, img_size=imageSize, data_root=dataroot, num_workers=1)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def getNonTargetDataSet(data_type, batch_size, imageSize, dataroot):\n",
        "    if data_type == 'cifar10':\n",
        "        _, test_loader = getCIFAR10(batch_size=batch_size, img_size=imageSize, data_root=dataroot, num_workers=1)\n",
        "    elif data_type == 'svhn':\n",
        "        _, test_loader = getSVHN(batch_size=batch_size, img_size=imageSize, data_root=dataroot, num_workers=1)\n",
        "    elif data_type == 'imagenet':\n",
        "        testsetout = datasets.ImageFolder(dataroot+\"/Imagenet_resize\", transform=transforms.Compose([transforms.Scale(imageSize),transforms.ToTensor()]))\n",
        "        test_loader = torch.utils.data.DataLoader(testsetout, batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "    elif data_type == 'lsun':\n",
        "        testsetout = datasets.ImageFolder(dataroot+\"/LSUN_resize\", transform=transforms.Compose([transforms.Scale(imageSize),transforms.ToTensor()]))\n",
        "        test_loader = torch.utils.data.DataLoader(testsetout, batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "\n",
        "    return test_loader\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-af7e6c4862e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo install torch, click the button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KnX8P4Bgx4f8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}