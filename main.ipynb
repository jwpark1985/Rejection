{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jwpark1985/Rejection/blob/master/main.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "1hs-RBSvxUsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "98882847-446b-4031-8060-4830cc688e22"
      },
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "# This code is based on samples from pytorch #\n",
        "##############################################\n",
        "# Writer: Kimin Lee \n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import data_loader\n",
        "import numpy as np\n",
        "import torchvision.utils as vutils\n",
        "import models\n",
        "\n",
        "from torch.utils.serialization import load_lua\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser(description='Training code - cross entropy')\n",
        "parser.add_argument('--batch-size', type=int, default=128, help='input batch size for training')\n",
        "parser.add_argument('--epochs', type=int, default=100, help='number of epochs to train')\n",
        "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate')\n",
        "parser.add_argument('--no-cuda', action='store_true', default=False, help='disables CUDA training')\n",
        "parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
        "parser.add_argument('--log-interval', type=int, default=100, help='how many batches to wait before logging training status')\n",
        "parser.add_argument('--dataset', default='cifar10', help='cifar10 | svhn')\n",
        "parser.add_argument('--dataroot', required=True, help='path to dataset')\n",
        "parser.add_argument('--imageSize', type=int, default=32, help='the height / width of the input image to network')\n",
        "parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')\n",
        "parser.add_argument('--wd', type=float, default=0.0, help='weight decay')\n",
        "parser.add_argument('--droprate', type=float, default=0.1, help='learning rate decay')\n",
        "parser.add_argument('--decreasing_lr', default='60', help='decreasing strategy')\n",
        "\n",
        "args = parser.parse_args()\n",
        "print(args)\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "print(\"Random Seed: \", args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
        "\n",
        "print('load data: ',args.dataset)\n",
        "train_loader, test_loader = data_loader.getTargetDataSet(args.dataset, args.batch_size, args.imageSize, args.dataroot)\n",
        "\n",
        "print('Load model')\n",
        "model = models.vgg13()\n",
        "print(model)\n",
        "\n",
        "if args.cuda:\n",
        "    model.cuda()\n",
        "\n",
        "print('Setup optimizer')\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
        "decreasing_lr = list(map(int, args.decreasing_lr.split(',')))\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if args.cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = F.log_softmax(model(data))\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data, target in test_loader:\n",
        "        total += data.size(0)\n",
        "        if args.cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = F.log_softmax(model(data))\n",
        "        test_loss += F.nll_loss(output, target).data[0]\n",
        "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "\n",
        "    test_loss = test_loss\n",
        "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, total,\n",
        "        100. * correct / total))\n",
        "\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(epoch)\n",
        "    if epoch in decreasing_lr:\n",
        "        optimizer.param_groups[0]['lr'] *= args.droprate\n",
        "    test(epoch)\n",
        "    if epoch % 50 == 0:\n",
        "        torch.save(model.state_dict(), '%s/model_epoch_%d.pth' % (args.outf, epoch))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-555dd9304299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_loader'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "yrIi0LskG2Fq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tQJBxzlUGs3l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "diq78U1giIj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c3pbin-uiJkQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KnX8P4Bgx4f8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}